2023-04-12 06:54:09,768 ===> Epoch[1/100]
2023-04-12 07:10:45,365 >>> Training Loss: 0.000007368379556 ### Testing Loss: 0.000003153855914
2023-04-12 07:10:45,365 ===> Epoch[2/100]
2023-04-12 07:27:09,094 >>> Training Loss: 0.000006109859896 ### Testing Loss: 0.000002871329571
2023-04-12 07:27:09,094 ===> Epoch[3/100]
2023-04-12 07:43:36,522 >>> Training Loss: 0.000005633205092 ### Testing Loss: 0.000002677090379
2023-04-12 07:43:36,522 ===> Epoch[4/100]
2023-04-12 08:00:05,547 >>> Training Loss: 0.000005335749847 ### Testing Loss: 0.000002568635182
2023-04-12 08:00:05,547 ===> Epoch[5/100]
2023-04-12 08:16:35,659 >>> Training Loss: 0.000005103651802 ### Testing Loss: 0.000002601591177
2023-04-12 08:16:35,659 ===> Epoch[6/100]
2023-04-12 08:33:06,265 >>> Training Loss: 0.000004884521331 ### Testing Loss: 0.000002359704467
2023-04-12 08:33:06,265 ===> Epoch[7/100]
2023-04-12 08:49:37,225 >>> Training Loss: 0.000004732606158 ### Testing Loss: 0.000002345405846
2023-04-12 08:49:37,225 ===> Epoch[8/100]
2023-04-12 09:06:08,800 >>> Training Loss: 0.000004563228231 ### Testing Loss: 0.000002415633389
2023-04-12 09:06:08,800 ===> Epoch[9/100]
2023-04-12 09:22:59,607 >>> Training Loss: 0.000004436407380 ### Testing Loss: 0.000002248542160
2023-04-12 09:22:59,607 ===> Epoch[10/100]
2023-04-12 09:39:33,047 >>> Training Loss: 0.000004321280358 ### Testing Loss: 0.000002200036306
2023-04-12 09:39:33,047 ===> Epoch[11/100]
2023-04-12 09:56:06,437 >>> Training Loss: 0.000004387135505 ### Testing Loss: 0.000002255761956
2023-04-12 09:56:06,437 ===> Epoch[12/100]
2023-04-12 10:12:39,831 >>> Training Loss: 0.000004144771083 ### Testing Loss: 0.000002127833113
2023-04-12 10:12:39,831 ===> Epoch[13/100]
2023-04-12 10:29:14,144 >>> Training Loss: 0.000004039305622 ### Testing Loss: 0.000002125396122
2023-04-12 10:29:14,144 ===> Epoch[14/100]
2023-04-12 10:45:49,357 >>> Training Loss: 0.000003923187705 ### Testing Loss: 0.000002103931138
2023-04-12 10:45:49,357 ===> Epoch[15/100]
2023-04-12 11:02:24,175 >>> Training Loss: 0.000003825435215 ### Testing Loss: 0.000002050649073
2023-04-12 11:02:24,175 ===> Epoch[16/100]
2023-04-12 11:18:59,229 >>> Training Loss: 0.000003795211114 ### Testing Loss: 0.000002031820713
2023-04-12 11:18:59,229 ===> Epoch[17/100]
2023-04-12 11:35:34,632 >>> Training Loss: 0.000003772950322 ### Testing Loss: 0.000002023605703
2023-04-12 11:35:34,642 ===> Epoch[18/100]
2023-04-12 11:52:10,293 >>> Training Loss: 0.000003754197678 ### Testing Loss: 0.000002178726618
2023-04-12 11:52:10,293 ===> Epoch[19/100]
2023-04-12 12:08:45,991 >>> Training Loss: 0.000003731255674 ### Testing Loss: 0.000001998535254
2023-04-12 12:08:45,991 ===> Epoch[20/100]
2023-04-12 12:25:22,333 >>> Training Loss: 0.000003709538078 ### Testing Loss: 0.000002075684051
2023-04-12 12:25:22,333 ===> Epoch[21/100]
2023-04-12 12:41:58,692 >>> Training Loss: 0.000003688913694 ### Testing Loss: 0.000001939108643
2023-04-12 12:41:58,692 ===> Epoch[22/100]
2023-04-12 12:58:35,323 >>> Training Loss: 0.000003674104619 ### Testing Loss: 0.000002008865067
2023-04-12 12:58:35,323 ===> Epoch[23/100]
2023-04-12 13:15:11,808 >>> Training Loss: 0.000003650360668 ### Testing Loss: 0.000001995762432
2023-04-12 13:15:11,808 ===> Epoch[24/100]
2023-04-12 13:31:49,072 >>> Training Loss: 0.000003634283530 ### Testing Loss: 0.000001934186002
2023-04-12 13:31:49,072 ===> Epoch[25/100]
2023-04-12 13:48:26,718 >>> Training Loss: 0.000003611042757 ### Testing Loss: 0.000002022350372
2023-04-12 13:48:26,718 ===> Epoch[26/100]
2023-04-12 14:05:04,978 >>> Training Loss: 0.000003595754379 ### Testing Loss: 0.000001996630090
2023-04-12 14:05:04,978 ===> Epoch[27/100]
2023-04-12 14:21:43,263 >>> Training Loss: 0.000003567400654 ### Testing Loss: 0.000001923107220
2023-04-12 14:21:43,263 ===> Epoch[28/100]
2023-04-12 14:38:21,692 >>> Training Loss: 0.000003548935410 ### Testing Loss: 0.000002029643611
2023-04-12 14:38:21,692 ===> Epoch[29/100]
2023-04-12 14:55:00,278 >>> Training Loss: 0.000003544166248 ### Testing Loss: 0.000002002863084
2023-04-12 14:55:00,278 ===> Epoch[30/100]
2023-04-12 15:11:39,204 >>> Training Loss: 0.000003540177886 ### Testing Loss: 0.000002010278422
2023-04-12 15:11:39,204 ===> Epoch[31/100]
2023-04-12 15:28:34,619 >>> Training Loss: 0.000003536985332 ### Testing Loss: 0.000002083513664
2023-04-12 15:28:34,619 ===> Epoch[32/100]
2023-04-12 15:45:14,905 >>> Training Loss: 0.000003532850087 ### Testing Loss: 0.000001974156248
2023-04-12 15:45:14,905 ===> Epoch[33/100]
2023-04-12 16:01:54,497 >>> Training Loss: 0.000003528947673 ### Testing Loss: 0.000001987242968
2023-04-12 16:01:54,497 ===> Epoch[34/100]
2023-04-12 16:18:33,438 >>> Training Loss: 0.000003525376769 ### Testing Loss: 0.000001929282234
2023-04-12 16:18:33,438 ===> Epoch[35/100]
2023-04-12 16:35:12,547 >>> Training Loss: 0.000003520449582 ### Testing Loss: 0.000002054776360
2023-04-12 16:35:12,547 ===> Epoch[36/100]
2023-04-12 16:51:55,104 >>> Training Loss: 0.000003517596951 ### Testing Loss: 0.000002197030881
2023-04-12 16:51:55,104 ===> Epoch[37/100]
2023-04-12 17:08:33,831 >>> Training Loss: 0.000003513345746 ### Testing Loss: 0.000001955873131
2023-04-12 17:08:33,831 ===> Epoch[38/100]
2023-04-12 17:25:12,994 >>> Training Loss: 0.000003509728003 ### Testing Loss: 0.000002017624183
2023-04-12 17:25:12,994 ===> Epoch[39/100]
2023-04-12 17:41:50,506 >>> Training Loss: 0.000003506105713 ### Testing Loss: 0.000001977186002
2023-04-12 17:41:50,506 ===> Epoch[40/100]
2023-04-12 17:58:28,055 >>> Training Loss: 0.000003501662377 ### Testing Loss: 0.000001985657718
2023-04-12 17:58:28,055 ===> Epoch[41/100]
2023-04-12 18:15:05,546 >>> Training Loss: 0.000003496372983 ### Testing Loss: 0.000002032271141
2023-04-12 18:15:05,546 ===> Epoch[42/100]
2023-04-12 18:31:42,519 >>> Training Loss: 0.000003495285455 ### Testing Loss: 0.000001946623115
2023-04-12 18:31:42,519 ===> Epoch[43/100]
2023-04-12 18:48:18,910 >>> Training Loss: 0.000003493922577 ### Testing Loss: 0.000001956541382
2023-04-12 18:48:18,910 ===> Epoch[44/100]
2023-04-12 19:04:55,249 >>> Training Loss: 0.000003493195663 ### Testing Loss: 0.000002016201051
2023-04-12 19:04:55,249 ===> Epoch[45/100]
2023-04-12 19:21:31,592 >>> Training Loss: 0.000003492276164 ### Testing Loss: 0.000001968084462
2023-04-12 19:21:31,592 ===> Epoch[46/100]
2023-04-12 19:38:07,493 >>> Training Loss: 0.000003491280722 ### Testing Loss: 0.000002012355253
2023-04-12 19:38:07,493 ===> Epoch[47/100]
2023-04-12 19:54:48,427 >>> Training Loss: 0.000003490522658 ### Testing Loss: 0.000002002551355
2023-04-12 19:54:48,427 ===> Epoch[48/100]
2023-04-12 20:11:23,729 >>> Training Loss: 0.000003489448545 ### Testing Loss: 0.000001986714096
2023-04-12 20:11:23,729 ===> Epoch[49/100]
2023-04-12 20:27:58,673 >>> Training Loss: 0.000003488513812 ### Testing Loss: 0.000002083220124
2023-04-12 20:27:58,673 ===> Epoch[50/100]
2023-04-12 20:44:33,492 >>> Training Loss: 0.000003487759614 ### Testing Loss: 0.000002028175231
2023-04-12 20:44:33,492 ===> Epoch[51/100]
2023-04-12 21:01:07,868 >>> Training Loss: 0.000003486737342 ### Testing Loss: 0.000002024741661
2023-04-12 21:01:07,868 ===> Epoch[52/100]
2023-04-12 21:17:41,765 >>> Training Loss: 0.000003485532943 ### Testing Loss: 0.000001967857543
2023-04-12 21:17:41,765 ===> Epoch[53/100]
2023-04-12 21:34:26,285 >>> Training Loss: 0.000003485026355 ### Testing Loss: 0.000001918995622
2023-04-12 21:34:26,285 ===> Epoch[54/100]
2023-04-12 21:51:03,996 >>> Training Loss: 0.000003483955425 ### Testing Loss: 0.000001995578486
2023-04-12 21:51:03,996 ===> Epoch[55/100]
2023-04-12 22:07:37,550 >>> Training Loss: 0.000003483111641 ### Testing Loss: 0.000002017342695
2023-04-12 22:07:37,550 ===> Epoch[56/100]
2023-04-12 22:24:11,009 >>> Training Loss: 0.000003482176453 ### Testing Loss: 0.000002056825679
2023-04-12 22:24:11,009 ===> Epoch[57/100]
2023-04-12 22:40:43,698 >>> Training Loss: 0.000003481307431 ### Testing Loss: 0.000001983126594
2023-04-12 22:40:43,698 ===> Epoch[58/100]
2023-04-12 22:57:15,835 >>> Training Loss: 0.000003480336090 ### Testing Loss: 0.000001935350610
2023-04-12 22:57:15,835 ===> Epoch[59/100]
2023-04-12 23:13:47,717 >>> Training Loss: 0.000003479472070 ### Testing Loss: 0.000002193262844
2023-04-12 23:13:47,717 ===> Epoch[60/100]
2023-04-12 23:30:19,308 >>> Training Loss: 0.000003478637609 ### Testing Loss: 0.000002039554602
2023-04-12 23:30:19,308 ===> Epoch[61/100]
2023-04-12 23:46:50,644 >>> Training Loss: 0.000003477714927 ### Testing Loss: 0.000002037631248
2023-04-12 23:46:50,644 ===> Epoch[62/100]
2023-04-13 00:03:22,090 >>> Training Loss: 0.000003476929805 ### Testing Loss: 0.000002030129735
2023-04-13 00:03:22,090 ===> Epoch[63/100]
2023-04-13 00:19:56,162 >>> Training Loss: 0.000003475757921 ### Testing Loss: 0.000001902742611
2023-04-13 00:19:56,162 ===> Epoch[64/100]
2023-04-13 00:36:27,434 >>> Training Loss: 0.000003475046242 ### Testing Loss: 0.000001987335963
2023-04-13 00:36:27,434 ===> Epoch[65/100]
2023-04-13 00:52:58,780 >>> Training Loss: 0.000003473905281 ### Testing Loss: 0.000002019859494
2023-04-13 00:52:58,780 ===> Epoch[66/100]
2023-04-13 01:09:29,553 >>> Training Loss: 0.000003473374818 ### Testing Loss: 0.000002013433232
2023-04-13 01:09:29,553 ===> Epoch[67/100]
2023-04-13 01:26:00,383 >>> Training Loss: 0.000003472399385 ### Testing Loss: 0.000001881950197
2023-04-13 01:26:00,383 ===> Epoch[68/100]
2023-04-13 01:42:30,562 >>> Training Loss: 0.000003471504215 ### Testing Loss: 0.000001991624003
2023-04-13 01:42:30,562 ===> Epoch[69/100]
2023-04-13 01:59:00,731 >>> Training Loss: 0.000003470542651 ### Testing Loss: 0.000001983711854
2023-04-13 01:59:00,731 ===> Epoch[70/100]
2023-04-13 02:15:30,039 >>> Training Loss: 0.000003469832791 ### Testing Loss: 0.000001949862281
2023-04-13 02:15:30,039 ===> Epoch[71/100]
2023-04-13 02:31:59,464 >>> Training Loss: 0.000003468630212 ### Testing Loss: 0.000002027881237
2023-04-13 02:31:59,464 ===> Epoch[72/100]
2023-04-13 02:48:28,384 >>> Training Loss: 0.000003467951046 ### Testing Loss: 0.000001974784482
2023-04-13 02:48:28,384 ===> Epoch[73/100]
2023-04-13 03:04:57,203 >>> Training Loss: 0.000003467022907 ### Testing Loss: 0.000002087391294
2023-04-13 03:04:57,203 ===> Epoch[74/100]
2023-04-13 03:21:25,939 >>> Training Loss: 0.000003466150702 ### Testing Loss: 0.000002117696113
2023-04-13 03:21:25,939 ===> Epoch[75/100]
2023-04-13 03:37:55,037 >>> Training Loss: 0.000003465421969 ### Testing Loss: 0.000002010749313
2023-04-13 03:37:55,037 ===> Epoch[76/100]
2023-04-13 03:54:42,578 >>> Training Loss: 0.000003464485189 ### Testing Loss: 0.000001903820248
2023-04-13 03:54:42,578 ===> Epoch[77/100]
2023-04-13 04:11:12,110 >>> Training Loss: 0.000003463544317 ### Testing Loss: 0.000002006894420
2023-04-13 04:11:12,110 ===> Epoch[78/100]
2023-04-13 04:27:41,919 >>> Training Loss: 0.000003462751010 ### Testing Loss: 0.000001907430715
2023-04-13 04:27:41,919 ===> Epoch[79/100]
2023-04-13 04:44:11,363 >>> Training Loss: 0.000003461751703 ### Testing Loss: 0.000002018687383
2023-04-13 04:44:11,363 ===> Epoch[80/100]
2023-04-13 05:00:40,440 >>> Training Loss: 0.000003461001597 ### Testing Loss: 0.000001995028242
2023-04-13 05:00:40,440 ===> Epoch[81/100]
2023-04-13 05:17:10,011 >>> Training Loss: 0.000003460058679 ### Testing Loss: 0.000001936250783
2023-04-13 05:17:10,011 ===> Epoch[82/100]
2023-04-13 05:33:39,188 >>> Training Loss: 0.000003459162144 ### Testing Loss: 0.000001996499805
2023-04-13 05:33:39,188 ===> Epoch[83/100]
2023-04-13 05:50:08,212 >>> Training Loss: 0.000003458425226 ### Testing Loss: 0.000002002100700
2023-04-13 05:50:08,212 ===> Epoch[84/100]
2023-04-13 06:06:37,529 >>> Training Loss: 0.000003457572575 ### Testing Loss: 0.000001919010856
2023-04-13 06:06:37,529 ===> Epoch[85/100]
2023-04-13 06:23:06,115 >>> Training Loss: 0.000003456560307 ### Testing Loss: 0.000001931281759
2023-04-13 06:23:06,115 ===> Epoch[86/100]
2023-04-13 06:39:34,563 >>> Training Loss: 0.000003455885462 ### Testing Loss: 0.000002057904794
2023-04-13 06:39:34,563 ===> Epoch[87/100]
2023-04-13 06:56:03,388 >>> Training Loss: 0.000003454864782 ### Testing Loss: 0.000001996102355
2023-04-13 06:56:03,388 ===> Epoch[88/100]
2023-04-13 07:12:32,443 >>> Training Loss: 0.000003454109674 ### Testing Loss: 0.000001936368335
2023-04-13 07:12:32,443 ===> Epoch[89/100]
2023-04-13 07:29:01,444 >>> Training Loss: 0.000003453226782 ### Testing Loss: 0.000001903871066
2023-04-13 07:29:01,444 ===> Epoch[90/100]
2023-04-13 07:45:30,573 >>> Training Loss: 0.000003452367764 ### Testing Loss: 0.000001915002031
2023-04-13 07:45:30,573 ===> Epoch[91/100]
2023-04-13 08:02:01,837 >>> Training Loss: 0.000003451616521 ### Testing Loss: 0.000001905613999
2023-04-13 08:02:01,837 ===> Epoch[92/100]
2023-04-13 08:18:34,954 >>> Training Loss: 0.000003450677696 ### Testing Loss: 0.000002024832156
2023-04-13 08:18:34,954 ===> Epoch[93/100]
2023-04-13 08:35:09,962 >>> Training Loss: 0.000003449879841 ### Testing Loss: 0.000002048368515
2023-04-13 08:35:09,962 ===> Epoch[94/100]
2023-04-13 08:51:47,201 >>> Training Loss: 0.000003448931466 ### Testing Loss: 0.000001907399337
2023-04-13 08:51:47,202 ===> Epoch[95/100]
2023-04-13 09:08:25,118 >>> Training Loss: 0.000003448152256 ### Testing Loss: 0.000002054452580
2023-04-13 09:08:25,118 ===> Epoch[96/100]
2023-04-13 09:25:03,473 >>> Training Loss: 0.000003447356448 ### Testing Loss: 0.000001952980710
2023-04-13 09:25:03,473 ===> Epoch[97/100]
2023-04-13 09:41:41,877 >>> Training Loss: 0.000003446425808 ### Testing Loss: 0.000001921516059
2023-04-13 09:41:41,877 ===> Epoch[98/100]
2023-04-13 09:58:32,831 >>> Training Loss: 0.000003445807579 ### Testing Loss: 0.000001903283646
2023-04-13 09:58:32,831 ===> Epoch[99/100]
2023-04-13 10:15:13,255 >>> Training Loss: 0.000003444732329 ### Testing Loss: 0.000001991049430
2023-04-13 10:15:13,255 ===> Epoch[100/100]
2023-04-13 10:31:52,470 >>> Training Loss: 0.000003444026788 ### Testing Loss: 0.000001960679583
